---
title: "Your Title"
subtitle: "BMIN503/EPID600 Final Project"
author: "FirstName LastName"
format: html
editor: visual
number-sections: true
embed-resources: true
---

------------------------------------------------------------------------

Use this template to complete your project throughout the course. Your Final Project presentation will be based on the contents of this document. Replace the title/name above and text below with your own, but keep the headers. Feel free to change the theme and other display settings, although this is not required. I added a new sentence

## Overview {#sec-overview}

The aim of this project is to develop a machine learning-based lung cancer detection system that assists physicians in identifying potentially malignant nodules by analyzing CT scan images, thereby improving diagnostic accuracy and efficiency. The core objectives of the project are to reduce the false-positive rate, decrease physicians' workload, and provide support for early lung cancer diagnosis.

## Introduction {#sec-introduction}

Lung cancer is one of the leading causes of cancer-related deaths globally and is usually detected at an advanced stage, resulting in limited treatment options. Early detection can significantly improve survival rates, but current diagnostic methods rely on extensive manual review of CT scan images by radiologists, a process that is both time-consuming and susceptible to subjective factors. The aim of this project is to develop a machine learning model to aid in the early diagnosis of lung cancer, with the goal of reducing false positives and improving diagnostic efficiency, thereby supporting clinicians. The project is inherently interdisciplinary, incorporating knowledge from oncology and machine learning. Oncologists provided insights into cancer progression, risk factors, and diagnostic challenges, while machine learning experts provided methods for model selection, data enhancement, and multimodal data integration.

I spoke with Dr. Mowery and Dr. Fan, who emphasized the importance of reducing the false-positive rate and provided clinical knowledge about key risk factors to help optimize early lung cancer diagnosis, and Dr. Mowery, who suggested integrating image data and clinical text annotations and proposed technical ideas for combining visual and non-visual data to improve prediction accuracy. I combined their claims of having made predictions with data and evaluated the predictions.

## Methods {#sec-methods}

Describe the data used and general methodological approach used to address the problem described in the @sec-introduction. Subsequently, incorporate full R code necessary to retrieve and clean data, and perform analysis. Be sure to include a description of code so that others (including your future self) can understand what you are doing and why.

```{r}
library(dplyr)
library(ggplot2)
library(readr)

options(warn = -1)

df <- read_csv('survey lung cancer.csv')

print(df)
```

**Note: In this dataset, YES=2 & NO=1**

```{r}
dim(df)

sum(duplicated(df))
df <- df[!duplicated(df), ]
colSums(is.na(df))
```

```{r}
str(df)
```

```{r}
summary(df)
```

```{r}
names(df) <- trimws(names(df))
print(names(df))
```

```{r}
df$GENDER <- as.numeric(factor(df$GENDER)) - 1
df$LUNG_CANCER <- as.numeric(factor(df$LUNG_CANCER)) - 1
df$SMOKING <- as.numeric(factor(df$SMOKING)) - 1
df$YELLOW_FINGERS <- as.numeric(factor(df$YELLOW_FINGERS)) - 1
df$ANXIETY <- as.numeric(factor(df$ANXIETY)) - 1
df$PEER_PRESSURE <- as.numeric(factor(df$PEER_PRESSURE)) - 1
df$`CHRONIC DISEASE` <- as.numeric(factor(df$`CHRONIC DISEASE`)) - 1
df$FATIGUE <- as.numeric(factor(df$FATIGUE)) - 1
df$ALLERGY <- as.numeric(factor(df$ALLERGY)) - 1
df$WHEEZING <- as.numeric(factor(df$WHEEZING)) - 1
df$`ALCOHOL CONSUMING` <- as.numeric(factor(df$`ALCOHOL CONSUMING`)) - 1
df$COUGHING <- as.numeric(factor(df$COUGHING)) - 1
df$`SHORTNESS OF BREATH` <- as.numeric(factor(df$`SHORTNESS OF BREATH`)) - 1
df$`SWALLOWING DIFFICULTY` <- as.numeric(factor(df$`SWALLOWING DIFFICULTY`)) - 1
df$`CHEST PAIN` <- as.numeric(factor(df$`CHEST PAIN`)) - 1

df

```

```{r}
str(df)
```

```{r}
ggplot(df, aes(x = as.factor(LUNG_CANCER), fill = as.factor(LUNG_CANCER))) +
  geom_bar() +
  scale_fill_manual(values = c("#0073C2FF", "#EFC000FF")) +
  labs(title = "Target Distribution", x = "LUNG_CANCER", y = "Count") +
  theme_minimal() +
  theme(legend.position = "none")
```

```{r}
table(df$LUNG_CANCER)

plot_distribution <- function(col_name, df) {
  library(ggplot2)
  
  ggplot(df, aes(x = as.factor(get(col_name)), fill = as.factor(LUNG_CANCER))) +
    geom_bar(position = "fill", stat = "count") +
    scale_fill_manual(values = c("#0073C2FF", "#EFC000FF")) +
    labs(
      title = paste("Distribution of LUNG_CANCER by", col_name),
      x = col_name,
      y = "Proportion"
    ) +
    theme_minimal()
}

plot_distribution("GENDER", df)
plot_distribution("AGE", df)
plot_distribution("SMOKING", df)
plot_distribution("YELLOW_FINGERS", df)
plot_distribution("ANXIETY", df)
plot_distribution("PEER_PRESSURE", df)
plot_distribution("CHRONIC DISEASE", df)
plot_distribution("FATIGUE", df)
plot_distribution("ALLERGY", df)
plot_distribution("WHEEZING", df)
plot_distribution("ALCOHOL CONSUMING", df)
plot_distribution("COUGHING", df)
plot_distribution("SHORTNESS OF BREATH", df)
plot_distribution("SWALLOWING DIFFICULTY", df)
plot_distribution("CHEST PAIN", df)
# Based on the visualizations, it is evident that the features GENDER, AGE, SMOKING, and SHORTNESS OF BREATH show minimal correlation with LUNG CANCER in the dataset. Therefore, we can remove these features to streamline and refine the dataset.
```

```{r}
df_new <- df %>% select(-GENDER, -AGE, -SMOKING, -`SHORTNESS OF BREATH`)
names(df_new) <- gsub(" ", "_", names(df_new))

print(names(df_new))

print(df_new)

```

```{r}
library(ggplot2)
library(reshape2)
library(corrplot)

df_numeric <- df_new[, sapply(df_new, is.numeric)]

cn <- cor(df_numeric, use = "complete.obs")

print(cn)

corrplot(cn, method = "color", col = colorRampPalette(c("blue", "white", "red"))(200),
         type = "full", 
         addCoef.col = "black",
         number.cex = 0.4,
         tl.cex = 0.2,
         tl.col = "black")
```

YELLOW_FINGERS and ANXIETY have a correlation of 0.56, showing a strong positive correlation. None of the other positive correlations are as high. For example, FATIGUE and CHRONIC_DISEASE have a correlation of -0.10, which is hardly linear. Most of the correlations between the variables are close to 0, which suggests that the variables may be independent or have a non-linear relationship.

```{r}
library(caret)

# 创建新变量
df_new$ANXYELFIN <- df_new$ANXIETY * df_new$YELLOW_FINGERS
print(df_new)

# 分割数据集为特征和目标变量
X <- df_new[, !(names(df_new) %in% c("LUNG_CANCER"))]
y <- df_new$LUNG_CANCER

# 检查目标变量分布
print(table(y))

# 数据集划分为训练集、验证集和测试集
set.seed(42)  # 确保结果可复现

# 首先划分训练集和临时集
train_index <- createDataPartition(y, p = 0.7, list = FALSE)
X_train <- X[train_index, ]
y_train <- y[train_index]
X_temp <- X[-train_index, ]
y_temp <- y[-train_index]

# 在临时集中划分验证集和测试集
set.seed(42)  # 确保结果一致
val_test_index <- createDataPartition(y_temp, p = 0.5, list = FALSE)
X_val <- X_temp[val_test_index, ]
y_val <- y_temp[val_test_index]
X_test <- X_temp[-val_test_index, ]
y_test <- y_temp[-val_test_index]

cat("Training set size: ", dim(X_train)[1], "\n")
cat("Validation set size: ", dim(X_val)[1], "\n")
cat("Test set size: ", dim(X_test)[1], "\n")

```

```{r}
train_data <- data.frame(y_train, X_train)
val_data <- data.frame(y_val, X_val)
test_data <- data.frame(y_test, X_test)

lr_model <- glm(y_train ~ ., data = train_data, family = binomial)

summary(lr_model)

y_val_pred <- predict(lr_model, newdata = val_data, type = "response")
y_val_pred <- ifelse(y_val_pred > 0.5, 1, 0)

confusion_matrix_val <- confusionMatrix(as.factor(y_val_pred), as.factor(y_val))
cat("\nValidation Set Performance:\n")
print(confusion_matrix_val)

y_test_pred <- predict(lr_model, newdata = test_data, type = "response")
y_test_pred <- ifelse(y_test_pred > 0.5, 1, 0)

confusion_matrix_test <- confusionMatrix(as.factor(y_test_pred), as.factor(y_test))
cat("\nTest Set Performance:\n")
print(confusion_matrix_test)
```

```{r}
library(rpart)
library(caret)

tree_model <- rpart(y_train ~ ., data = data.frame(y_train, X_train), method = "class")

y_val_pred_tree <- predict(tree_model, newdata = data.frame(X_val), type = "class")
confusion_matrix_val_tree <- confusionMatrix(y_val_pred_tree, as.factor(y_val))
cat("\nValidation Set Performance (Decision Tree):\n")
print(confusion_matrix_val_tree)

y_test_pred_tree <- predict(tree_model, newdata = data.frame(X_test), type = "class")
confusion_matrix_test_tree <- confusionMatrix(y_test_pred_tree, as.factor(y_test))
cat("\nTest Set Performance (Decision Tree):\n")
print(confusion_matrix_test_tree)

```

```{r}
library(randomForest)
library(caret)

y_train <- factor(y_train, levels = c(0, 1))
y_val <- factor(y_val, levels = c(0, 1))
y_test <- factor(y_test, levels = c(0, 1))

rf_model <- randomForest(y_train ~ ., data = data.frame(y_train, X_train), ntree = 100)

y_val_pred_rf <- predict(rf_model, newdata = data.frame(X_val))

y_val_pred_rf <- factor(y_val_pred_rf, levels = levels(y_val))

confusion_matrix_val_rf <- confusionMatrix(y_val_pred_rf, y_val)
cat("\nValidation Set Performance (Random Forest):\n")
print(confusion_matrix_val_rf)

y_test_pred_rf <- predict(rf_model, newdata = data.frame(X_test))

y_test_pred_rf <- factor(y_test_pred_rf, levels = levels(y_test))

confusion_matrix_test_rf <- confusionMatrix(y_test_pred_rf, y_test)
cat("\nTest Set Performance (Random Forest):\n")
print(confusion_matrix_test_rf)

```

## Results {#sec-results}

Describe your results and include relevant tables, plots, and code/comments used to obtain them. You may refer to the @sec-methods as needed. End with a brief conclusion of your findings related to the question you set out to address. You can include references if you'd like, but this is not required.

## Conclusion

This the conclusion. The @sec-results can be invoked here.
